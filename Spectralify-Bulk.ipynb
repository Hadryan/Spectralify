{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4007a-ffad-4555-9ede-6631cf2ce0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Instructions and Directory Path\n",
    "\"\"\"\n",
    "Getting Started: \n",
    "1. Get all of the required imports\n",
    "pip install librosa numpy pandas scipy mutagen audioread\n",
    "\n",
    "2. Change the path to the path of the music directory, artist, album, or song you want to analyze\n",
    "\n",
    "3. Adjustable Variables For Smoother Extraction:\n",
    "* Batch Size- If you're processing a large music collection and encounter memory issues, reduce the batch size in the run_analysis() function:\n",
    "* Worker Count- By default, the code uses 75% of available CPU cores. Adjust if needed (num_workers)\n",
    "\"\"\"\n",
    "\n",
    "#music_directory = \"C:\\\\Users\\\\[User_Name]\\\\Music\" # Change Me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb0cd4-d793-4ca9-9438-5e0eb0399923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and Tag Mapping\n",
    "\"\"\"\n",
    "Core imports and configuration setup\n",
    "Organized by functionality\n",
    "\"\"\"\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import warnings\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "#from IPython.display import HTML\n",
    "import time\n",
    "\n",
    "# Audio processing imports\n",
    "import librosa\n",
    "import audioread\n",
    "#from audioread import rawread\n",
    "from mutagen.flac import FLAC\n",
    "from mutagen.mp3 import MP3\n",
    "from mutagen.wave import WAVE\n",
    "from mutagen.aac import AAC\n",
    "from mutagen.aiff import AIFF\n",
    "from mutagen.id3 import ID3\n",
    "\n",
    "# Data handling imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants and configurations\n",
    "SUPPORTED_FORMATS = {\n",
    "    '.flac': ['audio/flac', FLAC],\n",
    "    '.mp3': ['audio/mp3', MP3],\n",
    "    '.wav': ['audio/wav', WAVE],\n",
    "    '.aac': ['audio/aac', AAC],\n",
    "    '.aiff': ['audio/aiff', AIFF],\n",
    "    '.wma': ['audio/wma', None]  # Requires additional handling\n",
    "}\n",
    "\n",
    "# Tag mapping for other audio formats\n",
    "AUDIO_TAG_MAPPING = {\n",
    "    'title': 'Title',\n",
    "    'artist': 'Artist',\n",
    "    'album': 'Album',\n",
    "    # Common variations\n",
    "    'TITLE': 'Title',\n",
    "    'ARTIST': 'Artist',\n",
    "    'ALBUM': 'Album'\n",
    "}\n",
    "\n",
    "ID3_TAG_MAPPING = {\n",
    "    'TIT2': 'Title',     # Title/songname/content description\n",
    "    'TPE1': 'Artist',    # Lead performer(s)/Soloist(s)\n",
    "    'TALB': 'Album',     # Album/Movie/Show title\n",
    "\n",
    "    # Alternate tag names for backwards compatibility\n",
    "    'TT2': 'Title',      # ID3v2.2 equivalent of TIT2\n",
    "    'TP1': 'Artist',     # ID3v2.2 equivalent of TPE1\n",
    "    'TAL': 'Album',      # ID3v2.2 equivalent of TALB\n",
    "}\n",
    "\n",
    "def extract_metadata_mp3(audio_meta):\n",
    "    \"\"\"Extract metadata specifically from MP3 files\"\"\"\n",
    "    metadata = {\n",
    "        'Title': '',\n",
    "        'Artist': '',\n",
    "        'Album': '',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if hasattr(audio_meta, 'tags') and audio_meta.tags:\n",
    "            # Standard ID3 tags\n",
    "            for id3_key, meta_key in ID3_TAG_MAPPING.items():\n",
    "                if id3_key in audio_meta.tags:\n",
    "                    tag_value = audio_meta.tags[id3_key]\n",
    "                    if hasattr(tag_value, 'text'):\n",
    "                        metadata[meta_key] = str(tag_value.text[0])\n",
    "                    else:\n",
    "                        metadata[meta_key] = str(tag_value)\n",
    "            \n",
    "            # Try alternate tag names if standard ones aren't found\n",
    "            if not metadata['Title'] and 'TIT1' in audio_meta.tags:\n",
    "                metadata['Title'] = str(audio_meta.tags['TIT1'].text[0])\n",
    "            if not metadata['Artist'] and 'TPE2' in audio_meta.tags:\n",
    "                metadata['Artist'] = str(audio_meta.tags['TPE2'].text[0])\n",
    "    except Exception as e:\n",
    "        print(f\"MP3 metadata extraction error: {str(e)}\")\n",
    "        \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a63bc-e72a-45ed-8249-dcf1f4bb625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Progress Tracker\n",
    "class ProgressTracker:\n",
    "    def __init__(self, total: int, description: str = \"Processing\", bar_length: int = 50):\n",
    "        self.total = total\n",
    "        self.current = 0\n",
    "        self.start_time = time.time()\n",
    "        self.description = description\n",
    "        self.bar_length = bar_length\n",
    "        \n",
    "    def update(self, amount: int = 1) -> None:\n",
    "        \"\"\"Update progress and display the progress bar\"\"\"\n",
    "        self.current += amount\n",
    "        self._display_progress()\n",
    "        \n",
    "    def _format_time(self, seconds: float) -> str:\n",
    "        \"\"\"Convert seconds to a human-readable format\"\"\"\n",
    "        return str(timedelta(seconds=int(seconds)))\n",
    "        \n",
    "    def _calculate_eta(self) -> Optional[float]:\n",
    "        \"\"\"Calculate estimated time remaining\"\"\"\n",
    "        if self.current == 0:\n",
    "            return None\n",
    "        \n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        items_per_second = self.current / elapsed_time\n",
    "        remaining_items = self.total - self.current\n",
    "        \n",
    "        return remaining_items / items_per_second if items_per_second > 0 else None\n",
    "        \n",
    "    def _display_progress(self) -> None:\n",
    "        \"\"\"Display progress bar with time estimates\"\"\"\n",
    "        percentage = min(100, (self.current / self.total) * 100)\n",
    "        filled_length = int(self.bar_length * self.current // self.total)\n",
    "        \n",
    "        # Create the progress bar\n",
    "        bar = '█' * filled_length + '░' * (self.bar_length - filled_length)\n",
    "        \n",
    "        # Calculate time metrics\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        eta = self._calculate_eta()\n",
    "        \n",
    "        # Format the progress message\n",
    "        progress_msg = (\n",
    "            f'\\r{self.description}: |{bar}| '\n",
    "            f'{percentage:>6.2f}% ({self.current}/{self.total}) '\n",
    "            f'[{self._format_time(elapsed_time)} elapsed'\n",
    "        )\n",
    "        \n",
    "        if eta is not None:\n",
    "            progress_msg += f' | ETA: {self._format_time(eta)}]'\n",
    "        else:\n",
    "            progress_msg += ']'\n",
    "            \n",
    "        # Print the progress\n",
    "        print(progress_msg, end='', flush=True)\n",
    "        \n",
    "        # Print newline if complete\n",
    "        if self.current >= self.total:\n",
    "            print(f\"\\nCompleted in {self._format_time(elapsed_time)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a58a5-b584-4bd6-82b0-f9f55fdee413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Metadata Extraction\n",
    "def extract_metadata_other(audio_meta):\n",
    "    \"\"\"Extract metadata from non-MP3 audio files\"\"\"\n",
    "    metadata = {\n",
    "        'Title': '',\n",
    "        'Artist': '',\n",
    "        'Album': '',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if hasattr(audio_meta, 'tags'):\n",
    "            for tag_key, tag_value in audio_meta.tags.items():\n",
    "                # Convert tag key to lowercase for consistent matching\n",
    "                tag_lower = tag_key.lower()\n",
    "                \n",
    "                # Try to match with known tag mappings\n",
    "                for known_key, meta_key in AUDIO_TAG_MAPPING.items():\n",
    "                    if known_key.lower() in tag_lower:\n",
    "                        # Handle different tag value formats\n",
    "                        if isinstance(tag_value, list):\n",
    "                            metadata[meta_key] = str(tag_value[0])\n",
    "                        elif isinstance(tag_value, (str, int, float)):\n",
    "                            metadata[meta_key] = str(tag_value)\n",
    "                        else:\n",
    "                            try:\n",
    "                                metadata[meta_key] = str(tag_value)\n",
    "                            except:\n",
    "                                continue\n",
    "                        break\n",
    "    except Exception as e:\n",
    "        print(f\"General metadata extraction error: {str(e)}\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def extract_metadata(audio_meta):\n",
    "    \"\"\"Extract metadata from audio file with enhanced format handling\"\"\"\n",
    "    try:\n",
    "        # Handle different audio formats\n",
    "        if isinstance(audio_meta, MP3):\n",
    "            metadata = extract_metadata_mp3(audio_meta)\n",
    "        else:\n",
    "            metadata = extract_metadata_other(audio_meta)\n",
    "        \n",
    "\n",
    "        return metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Metadata extraction failed: {str(e)}\")\n",
    "        return get_basic_metadata(None)\n",
    "\n",
    "def get_basic_metadata(file_path):\n",
    "    \"\"\"Get basic metadata from file path with improved parsing\"\"\"\n",
    "    metadata = {\n",
    "        'Title': 'Unknown Title',\n",
    "        'Album': 'Unknown Album',\n",
    "        'Artist': 'Unknown Artist'\n",
    "    }\n",
    "    \n",
    "    if file_path:\n",
    "        try:\n",
    "            path = Path(file_path)\n",
    "            \n",
    "            # Get title from filename\n",
    "            metadata['Title'] = path.stem\n",
    "            \n",
    "            # Get artist and album from directory structure\n",
    "            parts = list(path.parts)\n",
    "            if len(parts) > 2:\n",
    "                # Look for year pattern in album folder name\n",
    "                album_dir = parts[-2]\n",
    "                if '[' in album_dir and ']' in album_dir:\n",
    "                    # Extract album name without year\n",
    "                    metadata['Album'] = album_dir.split(']')[-1].strip()\n",
    "                else:\n",
    "                    metadata['Album'] = album_dir\n",
    "                \n",
    "                metadata['Artist'] = parts[-3]\n",
    "            elif len(parts) > 1:\n",
    "                metadata['Album'] = parts[-2]\n",
    "            \n",
    "            # Clean up values\n",
    "            for key in metadata:\n",
    "                if metadata[key]:\n",
    "                    # Remove file extensions, underscores, excessive spaces\n",
    "                    cleaned = metadata[key].replace('_', ' ').strip()\n",
    "                    # Remove common file prefixes/numbers\n",
    "                    if key == 'Title':\n",
    "                        cleaned = ' '.join(cleaned.split()[1:]) if cleaned.split() and cleaned.split()[0].isdigit() else cleaned\n",
    "                    metadata[key] = cleaned\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing file path metadata: {str(e)}\")\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283be0f-be91-40d9-a03f-aaf787df4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Audio Analysis, File Scanning, and Validation\n",
    "def analyze_audio_file(file_path, file_number):\n",
    "    \"\"\"Optimized audio file analysis with improved metadata handling\"\"\"\n",
    "    try:\n",
    "        # Load audio with optimized parameters\n",
    "        audio_data, sample_rate = librosa.load(\n",
    "            file_path, \n",
    "            sr=None,  # Preserve original sample rate\n",
    "            mono=True,  # Convert to mono\n",
    "        )\n",
    "        \n",
    "        # Get metadata based on file type\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        metadata_reader = SUPPORTED_FORMATS[ext][1]\n",
    "        \n",
    "        metadata = None\n",
    "        if metadata_reader:\n",
    "            try:\n",
    "                audio_meta = metadata_reader(file_path)\n",
    "                metadata = extract_metadata(audio_meta)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading metadata: {str(e)}\")\n",
    "                metadata = None\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(audio_data, sample_rate)\n",
    "        \n",
    "        # Combine metadata and features\n",
    "        analysis = {\n",
    "            **metadata,\n",
    "            **features\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError analyzing {os.path.basename(file_path)}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def validate_audio_file(file_path):\n",
    "    \"\"\"Validate if file is supported audio format\"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    return ext in SUPPORTED_FORMATS\n",
    "\n",
    "def get_audio_files(directory, track_selection='all'):\n",
    "    \"\"\"Get list of audio files based on selection\"\"\"\n",
    "    all_files = [f for f in os.listdir(directory) \n",
    "                 if validate_audio_file(f)]\n",
    "    all_files.sort()\n",
    "    \n",
    "    if track_selection == 'all':\n",
    "        return all_files\n",
    "    \n",
    "    try:\n",
    "        if '-' in track_selection:\n",
    "            start, end = map(int, track_selection.split('-'))\n",
    "            return all_files[start-1:end]\n",
    "        else:\n",
    "            tracks = list(map(int, track_selection.split(',')))\n",
    "            return [f for i, f in enumerate(all_files, 1) if i in tracks]\n",
    "    except:\n",
    "        print(\"Invalid track selection. Using all tracks.\")\n",
    "        return all_files\n",
    "\n",
    "def scan_music_directory(root_path):\n",
    "    \"\"\"Recursively scan directory for supported audio files with time tracking\"\"\"\n",
    "    audio_files = []\n",
    "    total_size = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"\\nScanning music directory...\")\n",
    "    print(\"This may take a while for large collections.\\n\")\n",
    "    \n",
    "    # Get total number of files for progress tracking\n",
    "    total_files = sum(len(files) for _, _, files in os.walk(root_path))\n",
    "    processed_files = 0\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        for filename in filenames:\n",
    "            processed_files += 1\n",
    "            if processed_files % 100 == 0:  # Update progress every 100 files\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = elapsed / processed_files\n",
    "                remaining = rate * (total_files - processed_files)\n",
    "                \n",
    "                progress = (processed_files / total_files) * 100\n",
    "                print(f\"\\rScanning: {processed_files}/{total_files} files ({progress:.1f}%) | \"\n",
    "                      f\"ETA: {remaining/60:.1f}\", end='', flush=True)\n",
    "                \n",
    "            if any(filename.lower().endswith(ext) for ext in SUPPORTED_FORMATS.keys()):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    size = os.path.getsize(file_path)\n",
    "                    total_size += size\n",
    "                    audio_files.append({\n",
    "                        'path': file_path,\n",
    "                        'size': size,\n",
    "                        'parent_dir': os.path.basename(dirpath)\n",
    "                    })\n",
    "                except OSError as e:\n",
    "                    print(f\"\\nError accessing file {file_path}: {str(e)}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n\\nScan complete!\")\n",
    "    print(f\"Found {len(audio_files)} audio files\")\n",
    "    \n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d7736-9853-48ab-a0a4-0e4e83de74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Key Detection and Feature Extraction\n",
    "def detect_key(chroma, y_harmonic, sr):\n",
    "    \"\"\"\n",
    "    Key detection using Krumhansl-Schmuckler key-finding algorithm\n",
    "    \n",
    "    \"\"\"\n",
    "    # Krumhansl-Schmuckler key profiles\n",
    "    major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
    "    minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
    "\n",
    "    # Normalize profiles\n",
    "    major_profile = major_profile / major_profile.sum()\n",
    "    minor_profile = minor_profile / minor_profile.sum()\n",
    "    \n",
    "    # Average and normalize chroma\n",
    "    mean_chroma = np.mean(chroma, axis=1)\n",
    "    mean_chroma = mean_chroma / (mean_chroma.sum() + 1e-8)\n",
    "    \n",
    "    # Initialize correlation scores\n",
    "    major_cors = []\n",
    "    minor_cors = []\n",
    "    \n",
    "    # Test all possible keys\n",
    "    for i in range(12):\n",
    "        # Rotate profiles to test each key\n",
    "        rolled_major = np.roll(major_profile, i)\n",
    "        rolled_minor = np.roll(minor_profile, i)\n",
    "        \n",
    "        # Calculate correlations\n",
    "        major_cor = np.corrcoef(mean_chroma, rolled_major)[0,1]\n",
    "        minor_cor = np.corrcoef(mean_chroma, rolled_minor)[0,1]\n",
    "        \n",
    "        major_cors.append(major_cor)\n",
    "        minor_cors.append(minor_cor)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    major_cors = np.array(major_cors)\n",
    "    minor_cors = np.array(minor_cors)\n",
    "    \n",
    "    # Find best key and mode\n",
    "    max_major_cor = np.max(major_cors)\n",
    "    max_minor_cor = np.max(minor_cors)\n",
    "    \n",
    "    if max_major_cor > max_minor_cor:\n",
    "        key_idx = np.argmax(major_cors)\n",
    "        mode = 'major'\n",
    "        confidence = max_major_cor\n",
    "    else:\n",
    "        key_idx = np.argmax(minor_cors)\n",
    "        mode = 'minor'\n",
    "        confidence = max_minor_cor\n",
    "    \n",
    "    # Map key index to key name\n",
    "    key_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    key = key_names[key_idx]\n",
    "    \n",
    "    # Calculate confidence score (0-1)\n",
    "    # Compare best correlation to mean of other correlations\n",
    "    if mode == 'major':\n",
    "        others_mean = np.mean(np.delete(major_cors, key_idx))\n",
    "        confidence = (confidence - others_mean) / (1 - others_mean + 1e-8)\n",
    "    else:\n",
    "        others_mean = np.mean(np.delete(minor_cors, key_idx))\n",
    "        confidence = (confidence - others_mean) / (1 - others_mean + 1e-8)\n",
    "    \n",
    "    confidence = max(0, min(1, confidence))  # Clip to [0,1]\n",
    "    \n",
    "    return key, mode, confidence\n",
    "\n",
    "\n",
    "def extract_features(audio_data, sr):\n",
    "    # \"\"\"Extract comprehensive audio features with improved spectral analysis and flattened output\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Cache commonly used computations\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
    "    y_harmonic = librosa.effects.harmonic(audio_data)\n",
    "    S = librosa.stft(audio_data)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio_data, sr=sr)\n",
    "    \n",
    "    # Use cached values instead of recomputing\n",
    "    chroma = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "    \n",
    "    # Batch compute MFCC features\n",
    "    mfccs_all = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "    mfcc_deltas = librosa.feature.delta(mfccs_all)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfccs_all, order=2)\n",
    "    \n",
    "    # Batch process spectral features using cached S\n",
    "    spectral_features = {\n",
    "        'centroids': librosa.feature.spectral_centroid(S=np.abs(S), sr=sr)[0],\n",
    "        'rolloff': librosa.feature.spectral_rolloff(S=np.abs(S), sr=sr)[0],\n",
    "        'bandwidth': librosa.feature.spectral_bandwidth(S=np.abs(S), sr=sr)[0],\n",
    "        'contrast': librosa.feature.spectral_contrast(S=np.abs(S), sr=sr)\n",
    "    }\n",
    "    \n",
    "    # Basic temporal features\n",
    "    features['Duration_Seconds'] = len(audio_data)/sr\n",
    "\n",
    "    # Calculate key correlation\n",
    "    chroma = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "    key, mode, confidence = detect_key(chroma, y_harmonic, sr)\n",
    "    features['Estimated_Key'] = f\"{key} {mode}\"\n",
    "    features['Key_Confidence'] = float(confidence)\n",
    "\n",
    "\n",
    "    # Pitch features with noise handling\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio_data, sr=sr)\n",
    "    valid_pitches = pitches[magnitudes > np.mean(magnitudes) * 0.1]  # Filter weak pitches\n",
    "    if len(valid_pitches) > 0:\n",
    "        features.update({\n",
    "            'Average_Pitch': float(np.mean(valid_pitches)),\n",
    "            'Pitch_Std': float(np.std(valid_pitches)),\n",
    "            'Pitch_Range': float(np.ptp(valid_pitches))\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'Average_Pitch': 0.0,\n",
    "            'Pitch_Std': 0.0,\n",
    "            'Pitch_Range': 0.0\n",
    "        })\n",
    "    \n",
    "    # pYIN pitch features\n",
    "    try:\n",
    "        # Downsample audio for pYIN if it's long\n",
    "        if len(audio_data) > sr * 30:  # If longer than 30 seconds\n",
    "            hop_length = 512  # Increased hop length for longer files\n",
    "        else:\n",
    "            hop_length = 256  # Default hop length for shorter files\n",
    "            \n",
    "        # Calculate pYIN with correct parameters\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "            audio_data,\n",
    "            sr=sr,\n",
    "            fmin=librosa.note_to_hz('C2'),  # Lower bound for pitch detection\n",
    "            fmax=librosa.note_to_hz('C7'),  # Upper bound for pitch detection\n",
    "            frame_length=2048,  # Reduced from default\n",
    "            hop_length=hop_length,\n",
    "            fill_na=None,  # Don't fill NaN values\n",
    "            center=False  # Disable centering to save memory\n",
    "        )\n",
    "        \n",
    "        # Process only valid pitch values\n",
    "        valid_f0 = f0[voiced_flag]\n",
    "        if len(valid_f0) > 0:\n",
    "            features.update({\n",
    "                'pYIN_Mean_Pitch': float(np.mean(valid_f0)),\n",
    "                'pYIN_Pitch_Std': float(np.std(valid_f0)),\n",
    "                'pYIN_Pitch_Range': float(np.ptp(valid_f0)),\n",
    "                'pYIN_Voiced_Rate': float(np.mean(voiced_flag)),\n",
    "                'pYIN_Mean_Confidence': float(np.mean(voiced_probs))\n",
    "            })\n",
    "            \n",
    "            # Additional pitch statistics only if we have enough data\n",
    "            if len(valid_f0) > 10:\n",
    "                # Calculate pitch stability\n",
    "                pitch_changes = np.diff(valid_f0)\n",
    "                features.update({\n",
    "                    'pYIN_Pitch_Stability': float(1.0 / (np.std(pitch_changes) + 1e-6)),\n",
    "                    'pYIN_Pitch_Clarity': float(np.max(voiced_probs) / (np.mean(voiced_probs) + 1e-6))\n",
    "                })\n",
    "            else:\n",
    "                features.update({\n",
    "                    'pYIN_Pitch_Stability': 0.0,\n",
    "                    'pYIN_Pitch_Clarity': 0.0\n",
    "                })\n",
    "        else:\n",
    "            # Set default values if no valid pitch found\n",
    "            features.update({\n",
    "                'pYIN_Mean_Pitch': 0.0,\n",
    "                'pYIN_Pitch_Std': 0.0,\n",
    "                'pYIN_Pitch_Range': 0.0,\n",
    "                'pYIN_Voiced_Rate': 0.0,\n",
    "                'pYIN_Mean_Confidence': 0.0,\n",
    "                'pYIN_Pitch_Stability': 0.0,\n",
    "                'pYIN_Pitch_Clarity': 0.0\n",
    "            })\n",
    "            \n",
    "        # Clean up\n",
    "        del f0\n",
    "        del voiced_flag\n",
    "        del voiced_probs\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: pYIN calculation failed - {str(e)}\")\n",
    "        features.update({\n",
    "            'pYIN_Mean_Pitch': 0.0,\n",
    "            'pYIN_Pitch_Std': 0.0,\n",
    "            'pYIN_Pitch_Range': 0.0,\n",
    "            'pYIN_Voiced_Rate': 0.0,\n",
    "            'pYIN_Mean_Confidence': 0.0,\n",
    "            'pYIN_Pitch_Stability': 0.0,\n",
    "            'pYIN_Pitch_Clarity': 0.0\n",
    "        })\n",
    "\n",
    "    # Harmonic features\n",
    "    features['Harmonic_Salience'] = float(np.mean(np.abs(y_harmonic)))\n",
    "\n",
    "    # Rhythm features\n",
    "    tempo, beats = librosa.beat.beat_track(y=audio_data, sr=sr)\n",
    "    features['Tempo_BPM'] = float(tempo)\n",
    "    \n",
    "    if len(beats) > 1:\n",
    "        beat_times = librosa.frames_to_time(beats, sr=sr)\n",
    "        beat_intervals = np.diff(beat_times)\n",
    "        features['Beat_Regularity'] = float(1.0 / (np.std(beat_intervals) + 1e-6))\n",
    "        features['Beat_Density'] = float(len(beats) / features['Duration_Seconds'])\n",
    "        features['Beat_Strength'] = float(np.mean(onset_env))\n",
    "        \n",
    "        # Calculate groove first\n",
    "        groove = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr)\n",
    "        features['Groove_Consistency'] = float(1.0 / (np.std(groove, axis=1).mean() + 1e-6))\n",
    "    else:\n",
    "        features['Beat_Regularity'] = 0.0\n",
    "        features['Beat_Density'] = 0.0\n",
    "        features['Beat_Strength'] = 0.0\n",
    "        features['Groove_Consistency'] = 0.0\n",
    "        \n",
    "    # Use the pre-computed spectral features from earlier\n",
    "    features.update({\n",
    "        'Average_Spectral_Centroid': float(np.mean(spectral_features['centroids'])),\n",
    "        'Spectral_Centroid_Std': float(np.std(spectral_features['centroids'])),\n",
    "        'Average_Spectral_Rolloff': float(np.mean(spectral_features['rolloff'])),\n",
    "        'Spectral_Rolloff_Std': float(np.std(spectral_features['rolloff'])),\n",
    "        'Average_Spectral_Bandwidth': float(np.mean(spectral_features['bandwidth'])),\n",
    "        'Spectral_Bandwidth_Std': float(np.std(spectral_features['bandwidth'])),\n",
    "        'Spectral_Contrast_Mean': float(np.mean(spectral_features['contrast'])),\n",
    "        'Spectral_Contrast_Std': float(np.std(spectral_features['contrast']))\n",
    "    })\n",
    "\n",
    "    S_norm = np.abs(S) / (np.sum(np.abs(S)) + 1e-10)\n",
    "    features['Spectral_Entropy'] = float(-np.sum(S_norm * np.log2(S_norm + 1e-10)))\n",
    "    features['Spectral_Flatness'] = float(np.mean(librosa.feature.spectral_flatness(y=audio_data)))\n",
    "\n",
    "    # Tonnetz features expanded\n",
    "    tonnetz = librosa.feature.tonnetz(y=y_harmonic, sr=sr)\n",
    "    for i in range(6):\n",
    "        features[f'Tonnetz_{i+1}'] = float(np.mean(tonnetz[i]))\n",
    "    \n",
    "    # Polynomial spectral coefficients expanded\n",
    "    poly_order = 4\n",
    "    freqs = librosa.fft_frequencies(sr=sr)\n",
    "    poly_coeffs = np.polyfit(np.arange(len(freqs)), np.mean(np.abs(S), axis=1), poly_order)\n",
    "    for i, coeff in enumerate(poly_coeffs):\n",
    "        features[f'Poly_Coefficient_{i+1}'] = float(coeff)\n",
    "\n",
    "    # Energy features\n",
    "    rms = librosa.feature.rms(y=audio_data)[0]\n",
    "    features['RMS_Energy_Mean'] = float(np.mean(rms))\n",
    "    features['RMS_Energy_Std'] = float(np.std(rms))\n",
    "    features['Dynamic_Range'] = float(np.max(rms) - np.min(rms))\n",
    "    features['Crest_Factor'] = float(np.max(np.abs(audio_data)) / np.sqrt(np.mean(audio_data**2)))\n",
    "\n",
    "    # PCEN energy\n",
    "    pcen = librosa.pcen(mel_spec)\n",
    "    features['PCEN_Energy_Mean'] = float(np.mean(pcen))\n",
    "    features['PCEN_Energy_Std'] = float(np.std(pcen))\n",
    "\n",
    "    # HPSS features\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(audio_data)\n",
    "    harmonic_energy = np.mean(y_harmonic**2)\n",
    "    percussive_energy = np.mean(y_percussive**2)\n",
    "    features['Harmonic_Energy'] = float(np.mean(np.abs(y_harmonic)))\n",
    "    features['Percussive_Energy'] = float(np.mean(np.abs(y_percussive)))\n",
    "    features['Harmonic_Ratio'] = float(harmonic_energy/(percussive_energy + 1e-10))\n",
    "    features['Tonal_Energy_Ratio'] = float(np.sum(y_harmonic**2) / (np.sum(audio_data**2) + 1e-10))\n",
    "\n",
    "    # Variable-Q transform features\n",
    "    VQT = librosa.vqt(audio_data, sr=sr)\n",
    "    features['VQT_Mean'] = float(np.mean(np.abs(VQT)))\n",
    "    features['VQT_Std'] = float(np.std(np.abs(VQT)))\n",
    "    # Clean up large variables for better performance\n",
    "    del VQT\n",
    "    gc.collect()\n",
    "\n",
    "    # Sub-bands for different instruments\n",
    "    bands = {\n",
    "        'bass': (20, 250),\n",
    "        'kick_drum': (40, 100),\n",
    "        'snare': (120, 600),\n",
    "        'cymbals': (2000, 16000),\n",
    "        'electric_guitar': (400, 4000),\n",
    "        'vocals': (200, 4000),\n",
    "        'synthesizer': (100, 8000)\n",
    "    }\n",
    "    \n",
    "    # Calculate normalized band energies\n",
    "    freqs = librosa.fft_frequencies(sr=sr)\n",
    "    for instrument, (low, high) in bands.items():\n",
    "        band_mask = np.logical_and(freqs >= low, freqs <= high)\n",
    "        band_energy = np.mean(np.abs(S)[band_mask])\n",
    "        total_energy = np.mean(np.abs(S))\n",
    "        features[f'{instrument}_presence'] = float(band_energy / (total_energy + 1e-8))\n",
    "    \n",
    "    # Additional instrument-specific features\n",
    "    features.update({\n",
    "        # Guitar detection using harmonic content\n",
    "        'guitar_distortion': float(np.mean(librosa.feature.spectral_flatness(y=y_harmonic))),\n",
    "        \n",
    "        # Drum detection using percussive content\n",
    "        'drum_prominence': float(np.mean(np.abs(y_percussive)) / (np.mean(np.abs(audio_data)) + 1e-8)),\n",
    "        \n",
    "        # Voice detection using harmonic-percussive separation\n",
    "        'vocal_harmonicity': float(np.mean(np.abs(y_harmonic)) / (np.mean(np.abs(y_percussive)) + 1e-8)),\n",
    "    })\n",
    "    \n",
    "    # Extended instrument analysis using onset patterns\n",
    "    onset_frames = librosa.onset.onset_detect(y=audio_data, sr=sr)\n",
    "    onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "    if len(onset_times) > 1:\n",
    "        # Analyze onset patterns for rhythm section detection\n",
    "        onset_intervals = np.diff(onset_times)\n",
    "        features.update({\n",
    "            'rhythm_regularity': float(1.0 / (np.std(onset_intervals) + 1e-8)),\n",
    "            'rhythm_density': float(len(onset_times) / (audio_data.shape[0] / sr)),\n",
    "            'drum_pattern_strength': float(np.mean(onset_env[onset_frames]))\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'rhythm_regularity': 0.0,\n",
    "            'rhythm_density': 0.0,\n",
    "            'drum_pattern_strength': 0.0\n",
    "        })\n",
    "\n",
    "    # Timbre classification using MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "    features.update({\n",
    "        'timbre_brightness': float(np.mean(mfccs[1:])),\n",
    "        'timbre_complexity': float(np.std(mfccs)),\n",
    "        'instrument_richness': float(np.mean(np.abs(librosa.feature.spectral_contrast(S=np.abs(S)))))\n",
    "    })\n",
    "    \n",
    "    # Vocal characteristics analysis\n",
    "    if features['vocals_presence'] > 0.3:  # Only if vocals are detected\n",
    "        # Pitch variation for vocal analysis\n",
    "        pitches, magnitudes = librosa.piptrack(y=audio_data, sr=sr)\n",
    "        strong_pitches = pitches[magnitudes > np.mean(magnitudes) * 0.5]\n",
    "        \n",
    "        if len(strong_pitches) > 0:\n",
    "            features.update({\n",
    "                'vocal_pitch_range': float(np.ptp(strong_pitches)),\n",
    "                'vocal_pitch_stability': float(1.0 / (np.std(strong_pitches) + 1e-8)),\n",
    "                'vocal_vibrato': float(np.std(np.diff(strong_pitches)))\n",
    "            })\n",
    "        else:\n",
    "            features.update({\n",
    "                'vocal_pitch_range': 0.0,\n",
    "                'vocal_pitch_stability': 0.0,\n",
    "                'vocal_vibrato': 0.0\n",
    "            })\n",
    "            \n",
    "        # Vocal formant analysis\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)[0]\n",
    "        features.update({\n",
    "            'vocal_formant_variation': float(np.std(spectral_rolloff)),\n",
    "            'vocal_clarity': float(np.mean(librosa.feature.spectral_contrast(y=audio_data, sr=sr)[2:5]))\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'vocal_pitch_range': 0.0,\n",
    "            'vocal_pitch_stability': 0.0,\n",
    "            'vocal_vibrato': 0.0,\n",
    "            'vocal_formant_variation': 0.0,\n",
    "            'vocal_clarity': 0.0\n",
    "        })\n",
    "\n",
    "    # Reassigned spectrogram features\n",
    "    freqs, times, mags = librosa.reassigned_spectrogram(audio_data)\n",
    "    features['Reassigned_Frequency_Mean'] = float(np.mean(freqs[np.abs(mags) > np.median(np.abs(mags))]))  # Only use significant magnitudes\n",
    "    features['Reassigned_Magnitude_Mean'] = float(np.mean(mags))\n",
    "\n",
    "    # Chroma features\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio_data, sr=sr)\n",
    "    features['Chroma_Mean'] = float(np.mean(chroma_stft))\n",
    "    features['Chroma_Std'] = float(np.std(chroma_stft))\n",
    "\n",
    "    # Zero crossing rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio_data)[0]\n",
    "    features['Zero_Crossing_Rate_Mean'] = float(np.mean(zcr))\n",
    "    features['Zero_Crossing_Rate_Std'] = float(np.std(zcr))\n",
    "\n",
    "    # MFCCs with deltas\n",
    "    for i, (mfcc, delta, delta2) in enumerate(zip(mfccs_all, mfcc_deltas, mfcc_delta2)):\n",
    "        features.update({\n",
    "            f'MFCC_{i+1}_Mean': float(np.mean(mfcc)),\n",
    "            f'MFCC_{i+1}_Std': float(np.std(mfcc)),\n",
    "            f'MFCC_{i+1}_Delta_Mean': float(np.mean(delta)),\n",
    "            f'MFCC_{i+1}_Delta_Std': float(np.std(delta)),\n",
    "            f'MFCC_{i+1}_Delta2_Mean': float(np.mean(delta2)),\n",
    "            f'MFCC_{i+1}_Delta2_Std': float(np.std(delta2))\n",
    "        })\n",
    "\n",
    "\n",
    "    # Rhythm and onset features\n",
    "    novelty = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)\n",
    "    features['Onset_Rate'] = float(len(novelty) / features['Duration_Seconds'])\n",
    "    features['Onset_Strength_Mean'] = float(np.mean(onset_env))\n",
    "    features['Onset_Strength_Std'] = float(np.std(onset_env))\n",
    "\n",
    "    # Tempogram features\n",
    "    ftempo = librosa.feature.fourier_tempogram(y=audio_data, sr=sr)\n",
    "    features['Tempogram_Mean'] = float(np.mean(np.abs(ftempo)))\n",
    "    features['Tempogram_Std'] = float(np.std(np.abs(ftempo)))\n",
    "\n",
    "    # Tempogram ratio features\n",
    "    tgram = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr)\n",
    "    features['Tempogram_Ratio'] = float(np.max(np.mean(tgram, axis=1)) / np.mean(tgram))\n",
    "\n",
    "    # Groove and pulse features\n",
    "    groove = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr)\n",
    "    pulse = librosa.beat.plp(onset_envelope=onset_env, sr=sr)\n",
    "    \n",
    "    features['Groove_Consistency'] = float(1.0 / (np.std(groove, axis=1).mean() + 1e-6))\n",
    "    features['Pulse_Clarity'] = float(min(1.0, np.mean(pulse)))\n",
    "\n",
    "    # HPSS separation measures\n",
    "    features['HPSS_Harmonic_Mean'] = float(np.mean(np.abs(y_harmonic)))\n",
    "    features['HPSS_Percussive_Mean'] = float(np.mean(np.abs(y_percussive)))\n",
    "    features['HPSS_Ratio'] = float(np.sum(np.abs(y_harmonic)) / (np.sum(np.abs(y_percussive)) + 1e-8))\n",
    "    # Clean up large variables for better performance\n",
    "    del y_harmonic\n",
    "    del y_percussive\n",
    "    gc.collect()\n",
    "\n",
    "    # Segmentation boundaries\n",
    "    boundaries = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)\n",
    "    boundary_times = librosa.frames_to_time(boundaries, sr=sr)\n",
    "\n",
    "    # Convert boundary times to statistics instead of array\n",
    "    features['Segment_Count'] = float(len(boundary_times))\n",
    "    if len(boundary_times) > 0:\n",
    "        features['Average_Segment_Duration'] = float(np.mean(np.diff(boundary_times)))\n",
    "        features['Segment_Duration_Std'] = float(np.std(np.diff(boundary_times))) if len(boundary_times) > 1 else 0.0\n",
    "        features['First_Segment_Time'] = float(boundary_times[0])\n",
    "        features['Last_Segment_Time'] = float(boundary_times[-1])\n",
    "    else:\n",
    "        features['Average_Segment_Duration'] = 0.0\n",
    "        features['Segment_Duration_Std'] = 0.0\n",
    "        features['First_Segment_Time'] = 0.0\n",
    "        features['Last_Segment_Time'] = 0.0\n",
    "\n",
    "    # Normalize features in [0-1] range\n",
    "    features['Key_Confidence'] = float(min(1.0, features['Key_Confidence']))\n",
    "    features['Harmonic_Salience'] = float(min(1.0, features['Harmonic_Salience']))\n",
    "\n",
    "    # Normalize spectral entropy\n",
    "    max_entropy = -np.log2(1.0/len(S))  # Maximum possible entropy\n",
    "    features['Spectral_Entropy'] = float(min(1.0, features['Spectral_Entropy'] / max_entropy))\n",
    "    features['Spectral_Flatness'] = float(min(1.0, features['Spectral_Flatness']))\n",
    "\n",
    "    # Bass Prominence\n",
    "    bass_band = librosa.fft_frequencies(sr=sr) <= 250\n",
    "    features['Bass_Prominence'] = float(np.mean(np.abs(S)[bass_band]) / np.mean(np.abs(S)))\n",
    "    \n",
    "    # Vocal Features\n",
    "    vocal_range = (200, 4000)  # Hz\n",
    "    vocal_band = np.logical_and(\n",
    "        librosa.mel_frequencies(n_mels=mel_spec.shape[0]) >= vocal_range[0],\n",
    "        librosa.mel_frequencies(n_mels=mel_spec.shape[0]) <= vocal_range[1]\n",
    "    )\n",
    "    features['Vocal_Presence'] = float(np.mean(mel_spec[vocal_band]) / np.mean(mel_spec))\n",
    "    \n",
    "    # Emotional Features\n",
    "    features['Emotional_Valence'] = float(\n",
    "        0.5 * (np.mean(spectral_features['centroids']) / (sr/2) + \n",
    "               min(features['Tempo_BPM']/180, 1))  # Use features['Tempo_BPM'] instead of tempo\n",
    "    )\n",
    "    features['Emotional_Arousal'] = float(\n",
    "        0.5 * (np.mean(onset_env) + \n",
    "               features['RMS_Energy_Mean'])  # Use already calculated RMS energy\n",
    "    )\n",
    "    \n",
    "    # Clean up large variables for better performance\n",
    "    del mel_spec\n",
    "    del S\n",
    "    gc.collect()\n",
    "\n",
    "    # Ensure all float values are Python float type\n",
    "    for key in features:\n",
    "        if isinstance(features[key], (np.float32, np.float64)):\n",
    "            features[key] = float(features[key])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651ddd1b-9df4-445e-bdb3-20d982a132e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Parallel Processing & File Output (CSV)\n",
    "def process_directory(directory, track_selection='all', num_workers=None):\n",
    "    \"\"\"Process directory of audio files in parallel with time estimation\"\"\"\n",
    "    if num_workers is None:\n",
    "        # Use 75% of available CPUs to avoid overwhelming system\n",
    "        num_workers = max(1, int(multiprocessing.cpu_count() * 0.75))\n",
    "    \n",
    "    # Use chunking for better memory management\n",
    "    chunk_size = 100  # Process files in chunks of 100\n",
    "    \n",
    "    audio_files = get_audio_files(directory, track_selection)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(audio_files), chunk_size):\n",
    "        chunk = audio_files[i:i + chunk_size]\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            futures = {executor.submit(analyze_audio_file, \n",
    "                                    os.path.join(directory, file), \n",
    "                                    idx): file \n",
    "                      for idx, file in enumerate(chunk)}\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                if future.result():\n",
    "                    results.append(future.result())\n",
    "    \n",
    "    return pd.DataFrame(results) if results else None\n",
    "\n",
    "def create_output_structure(base_path, analysis_name, timestamp):\n",
    "    \"\"\"Create organized output directory structure\"\"\"\n",
    "    # Create main output directory\n",
    "    output_dir = os.path.join(base_path, f\"{analysis_name}_{timestamp}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create subdirectories\n",
    "    viz_dir = os.path.join(output_dir, \"visualizations\")\n",
    "    data_dir = os.path.join(output_dir, \"data\")\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    return output_dir, viz_dir, data_dir\n",
    "\n",
    "def handle_csv_output(df_results):\n",
    "    \"\"\"Enhanced CSV output handling with organized directory structure\"\"\"\n",
    "    try:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        artist = df_results['Artist'].iloc[0] if 'Artist' in df_results.columns else 'Unknown'\n",
    "        analysis_type = {\n",
    "            '1': 'single_track',\n",
    "            '2': 'album',\n",
    "            '3': 'artist',\n",
    "            '4': 'library'\n",
    "        }.get(4, 'analysis')\n",
    "        base_name = f\"{artist}_{analysis_type}\"\n",
    "        \n",
    "        # Clean name for filesystem\n",
    "        base_name = \"\".join(x for x in base_name if x.isalnum() or x in (' ', '-', '_')).strip()\n",
    "        \n",
    "        # Create directory structure\n",
    "        output_dir, viz_dir, data_dir = create_output_structure(\n",
    "            music_directory, #same as input dir\n",
    "            base_name,\n",
    "            timestamp\n",
    "        )\n",
    "        \n",
    "        # Save CSV in data directory\n",
    "        csv_path = os.path.join(data_dir, f\"{base_name}_{timestamp}.csv\")\n",
    "        df_results.to_csv(csv_path, index=False)\n",
    "        \n",
    "        return output_dir, csv_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving results: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_scan_results(audio_files):\n",
    "    \"\"\"Process results from a full music directory scan with parallel processing\"\"\"\n",
    "    try:\n",
    "        total_files = len(audio_files)\n",
    "        print(f\"\\nInitializing analysis of {total_files} audio files...\")\n",
    "        \n",
    "        # Determine optimal number of workers\n",
    "        num_workers = min(multiprocessing.cpu_count(), total_files)\n",
    "        print(f\"Using {num_workers} parallel workers\\n\")\n",
    "        \n",
    "        all_results = []\n",
    "        lock = threading.Lock()\n",
    "        \n",
    "        # Initialize progress tracker\n",
    "        progress = ProgressTracker(total_files, \"Analyzing audio files\")\n",
    "        \n",
    "        def update_progress():\n",
    "            with lock:\n",
    "                progress.update()\n",
    "        \n",
    "        # Use ThreadPoolExecutor for parallel processing\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            future_to_file = {\n",
    "                executor.submit(\n",
    "                    analyze_audio_file,\n",
    "                    file_info['path'],\n",
    "                    idx + 1\n",
    "                ): file_info for idx, file_info in enumerate(audio_files)\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                for future in as_completed(future_to_file):\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        if result:\n",
    "                            all_results.append(result)\n",
    "                        update_progress()\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\nError processing {future_to_file[future]['path']}: {str(e)}\")\n",
    "                        update_progress()   \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nProcess interrupted by user.\")\n",
    "                executor.shutdown(wait=False)\n",
    "                return None\n",
    "        \n",
    "        if all_results:\n",
    "            return pd.DataFrame(all_results)\n",
    "        else:\n",
    "            print(\"No results generated from scan.\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing scan results: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab9370-4e05-4341-be7d-58202aff7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Kickstarting Analysis \n",
    "def run_analysis():\n",
    "    try:\n",
    "        # Create Analysis directory at the root of music_directory\n",
    "        analysis_dir = os.path.join(music_directory, \"Analysis\")\n",
    "        os.makedirs(analysis_dir, exist_ok=True)\n",
    "        \n",
    "        audio_files = scan_music_directory(music_directory)\n",
    "        if audio_files:\n",
    "            # Process in batches to manage memory\n",
    "            batch_size = 250\n",
    "            all_results = []\n",
    "            \n",
    "            for i in range(0, len(audio_files), batch_size):\n",
    "                batch = audio_files[i:i + batch_size]\n",
    "                results = process_scan_results(batch)\n",
    "                if results is not None:\n",
    "                    # Save after every batch to avoid crashes\n",
    "                    final_results = results\n",
    "                    \n",
    "                    # Save directly to Analysis folder\n",
    "                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                    artist = final_results['Artist'].iloc[0] if 'Artist' in final_results.columns else 'Unknown'\n",
    "                    base_name = f\"{artist}_analysis\"\n",
    "                    base_name = \"\".join(x for x in base_name if x.isalnum() or x in (' ', '-', '_')).strip()\n",
    "                    \n",
    "                    # Save CSV in Analysis directory\n",
    "                    csv_path = os.path.join(analysis_dir, f\"{base_name}_{timestamp}.csv\")\n",
    "                    final_results.to_csv(csv_path, index=False)\n",
    "                    \n",
    "                    print(f\"\\nResults saved to: {csv_path}\")\n",
    "                \n",
    "                # Force garbage collection after each batch\n",
    "                gc.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fbff29-86f8-441c-ae3f-8579a827ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Run Spectralify!\n",
    "run_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
